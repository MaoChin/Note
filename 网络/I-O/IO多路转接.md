# `I/O`多路转接

`select`，`poll`，`epoll`都是==解决“等”的问题==。通过监视文件描述符的状态变化：可读，可写，异常(如连接关闭，文件描述符非法等)，等待事件就绪。

这些方案可以一次等待多个文件描述符。但是这些方案也是要等待的，所以也会涉及到等待策略的问题：阻塞式？轮询？信号驱动？？

所有的多路转接方案都涉及到两个步骤：

1. 用户告诉内核，需要检测哪些文件描述符的哪些事件。
2. 内核告诉用户，让我检测的文件描述符中哪些文件描述符的哪些事件就绪了。

## 1. `select`

```C
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set 		  			*exceptfds, struct timeval *timeout);
```

1. `nfds`：等待的文件描述符中最大的那个 再 +1。(文件描述符就是数组下标)
2. `fd_set`：位图结构，比特位的位置代表所有的文件描述符编号，0/1代表是否就绪。
3. `readfds`：输入输出型参数。输入：需要监视“读”事件就绪的文件描述符；输出：“读”事件已经就绪的文件描述符。
4. `writefds`：输入输出型参数。输入：需要监视“写”事件就绪的文件描述符；输出：“写”事件已经就绪的文件描述符。
5. `exceptfds`：输入输出型参数。输入：需要监视“异常”事件就绪的文件描述符；输出：“异常”事件已经就绪的文件描述符。这三个输入输出参数用的同一张位图，所以每次修改会覆盖！==所以每次调用`select`，都要重新设置这三个参数！！==
6. `timeval`：等待策略，设置`deadline`，在`deadline`内阻塞等待，超过`deadline`就`timeout`返回。设置成`nullptr`表示一直阻塞。
7. 返回值：>0 ：有几个`fd`就绪。

​					<0 ：出错

​					==0：`timeout`了

```C
// fd_set 的设置接口
// 用来清除描述词组set中相关fd 的位
void FD_CLR(int fd, fd_set *set); 
// 用来测试描述词组set中相关fd 的位是否为真
int FD_ISSET(int fd, fd_set *set); 
// 用来设置描述词组set中相关fd的位
void FD_SET(int fd, fd_set *set); 
// 用来清除描述词组set的全部位
void FD_ZERO(fd_set *set); 
```

### 1. `select`编码特点

1. **每次调用`select`之前都要重置那三个输入输出型参数**；**`select`调用完成之后要对所有合法的`fd`进行遍历检测**，确定是那些`fd`事件就绪。
2. ==需要用户自己维护一个数组来存放所有合法的`fd`==，这样`select`才能进行批量处理。
3. 一旦某个`fd`的事件就绪，那么==这次==对这个`fd`的操作不会被阻塞！

### 2. `select`的优缺点

优点：

1. 对比多进程/多线程，`select`占用资源少，更高效。 

缺点：

1. 每一次调用都要重置那三个输入输出型参数！！麻烦且影响性能。
2. ==能够同时检测的`fd`数量有限==！！(`fd_set`位图是128字节，也就是只有128*8=1024个比特位，即最多只能同时检测1024个`fd`！！)
3. 每一次调用都需要从用户到内核，内核到用户传递参数。这中间的数据拷贝会影响性能。(这是多路转接都有的问题！)
4. ==每一次调用前和调用后都要遍历自己维护的合法`fd`数组，检测所有的`fd`==，调用前是为了重置参数，调用后是为了判断是哪一个`fd`就绪，效率低下！

## 2. `poll`

```C
int poll(struct pollfd *fds, nfds_t nfds, int timeout);

// pollfd结构
struct pollfd {
  int fd; 				// file descriptor 
  // 输入输出分离
  short events; 	// requested events  用户->内核
  short revents; 	// returned events 	 内核->用户
};
```

1. `fds`：`pollfd`的数组，也就是结构体数组。
2. `nfds`：`fds`数组的长度(元素个数)。
3. `timeout`：单位是毫秒，`timeout`时间内阻塞等待，0表示非阻塞，-1并表示一直阻塞等待。和`select`几乎一样。
4. 返回值：和`select`一模一样。
5. `events`：`short`2个字节，16比特位，每一位代表不同的事件。比如读事件，写事件，各种异常事件等。通过比特位传递信息，也是位图。

### 1. `poll`编码特点

1. 将输入和输出分开：`event`，`revent`。不用每一次调用前对参数进行重新设置！
2. **`poll`调用完成之后要对所有合法的`fd`进行遍历检测**，确定是那些`fd`事件就绪。
3. ==需要用户自己维护一个结构体数组来存放所有合法的`pollfd`结构体==。

### 2. `poll`的优缺点

优点：

1. 不用每一次调用前对参数进行重新设置！
2. **同时检测的`fd`数量可以非常多**，因为是用户自己维护的`pollfd`结构体数组。

缺点：

1. 还是需要用户自己维护`pollfd`结构体数组。
2. 一次调用都需要从用户到内核，内核到用户传递参数。这中间的数据拷贝会影响性能。(这是多路转接都有的问题！)
3. ==每一次调用后都要遍历自己维护的合法`pollfd`结构体数组，检测所有的`fd`==，判断是哪一个`fd`就绪，效率低下！

## 3. `epoll`

**一个完美的解决方案！！**一样的，只负责"等"！

```C
// epoll相关系统调用
// 1.创建一个epoll的句柄
int epoll_create(int size);
// 2.epoll的事件注册函数   用户 -> 内核
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
// 3.收集在epoll监控的事件中已经发生的事件  内核 -> 用户
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, 									int timeout);

// struct epoll_event
typedef union epoll_data {
  void    *ptr;
  int      fd;
  uint32_t u32;
  uint64_t u64;
} epoll_data_t;

struct epoll_event {
  uint32_t     events;    /* Epoll events */
  epoll_data_t data;      /* User data variable */
};
```

### 1. `epoll_create`(创建`epoll`模型) 

1. `size`现在已经被忽略了！直接设置成256(或者其他大于0的数)就可以了。
2. 返回值：一个文件描述符。可以理解为一个`epoll`模型。

### 2. `epoll_ctl`(==用户 -> 内核==)

这个函数就是负责把需要检测的文件描述符设置到`epoll`模型中，或者从`epoll`模型中删除掉对某些文件描述符的检测等。

1. `epfd`：`epoll_create`返回的那个文件描述符，指明要操作哪一个`epoll`模型。
2. `op`：操作方法，比如`EPOLL_CTL_ADD`，`EPOLL_CTL_MOD`，`EPOLL_CTL_DEL`。
3. `fd`：需要检测的文件描述符。
4. `event`：`fd`需要检测的事件。和`poll`一样，也是位图结构，每一个比特位代表不同的事件。

### 3. `epoll_wait`(==内核 -> 用户==)

这个函数是负责从内核获取事件就绪信息。

1. `epfd`：`epoll_create`返回的那个文件描述符，指明要操作哪一个`epoll`模型。

2. `events`：输出型参数，需要检测的事件中已经就绪的事件。

3. `timeout`：和`poll`一模一样。

4. 返回值：和`select`一模一样。

   

### 4. `epoll`底层原理

==`epoll`模型：回调机制+红黑树+就绪队列！！==这些都是内核做的，不需要用户关心！

当数据到达网卡后(读事件就绪)，**在硬件上会触发中断**，通知`CPU`有数据到来，然后`CPU`会通知`OS`，最后`OS`会调用内核的拷贝函数把网卡的数据拷贝到内核缓冲区，在这个拷贝函数中可以==设置回调！==

`epoll`针对一个或多个特定的`fd`会==设定对应的回调机制==，当`fd`缓冲区中有数据的时候会进行回调，也就是调用回调函数。回调函数主要处理以下事情：

1. 获取就绪的`fd`。
2. 获取就绪事件，检测该事件是不是用户让我关心的。
3. 构建`queue_node`节点并链入到就绪队列里。

另外，`epoll`模型中还会维护一棵红黑树：存放 ==用户 -> 内核 的信息==！

```C
// 红黑树节点  fd天然就可以作为红黑树的key !!!
struct rb_node
{
  // 表示用户关心的哪一个文件描述符的哪些事件
  int fd;
  int events;
  // ...
};
```

**所以`epoll_ctl`就是对红黑树进行增删查改！**

另外，`epoll`模型中还有一个就绪队列： 存放 ==内核 -> 用户 的信息==！

```C
// 就绪队列节点
struct queue_node
{
   // 表示红黑树中哪些节点的哪些事件已经就绪！
  int fd;
  int revents;
  // ...
};
```

**`epoll_wait`就是去检测就绪队列，有数据的话就把就绪队列的数据拿出来！！**检测的时间复杂度是O(1)的！而且内核往就绪队列里放数据，用户从就绪队列里取数据---生产者消费者模型！！！	

回想`TCP`协议中的`PSH`标志位，本质就是再往这个就绪队列里放数据，通知用户赶快读取。

### 5. `epoll`的优缺点







